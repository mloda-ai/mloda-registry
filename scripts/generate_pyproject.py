#!/usr/bin/env python3
"""Generate pyproject.toml files from shared configuration.

Usage:
    python scripts/generate_pyproject.py          # Generate all files
    python scripts/generate_pyproject.py --check  # Check if files are up-to-date
"""

from __future__ import annotations

import argparse
import re
import sys
from pathlib import Path
from typing import Any

if sys.version_info >= (3, 11):
    import tomllib
else:
    import tomli as tomllib  # type: ignore[import-not-found,unused-ignore]

CONFIG_DIR = Path("config")
SHARED_CONFIG = CONFIG_DIR / "shared.toml"
PACKAGES_CONFIG = CONFIG_DIR / "packages.toml"
ROOT_PYPROJECT = Path("pyproject.toml")

HEADER = """\
# AUTO-GENERATED by scripts/generate_pyproject.py
# Do not edit directly - modify config/shared.toml or config/packages.toml instead
"""


def to_toml_list(items: list[str]) -> str:
    """Format a list as TOML with double quotes."""
    quoted = [f'"{item}"' for item in items]
    return f"[{', '.join(quoted)}]"


def discover_packages(pkg_path: str, exclude_paths: list[str] | None = None) -> list[str]:
    """Discover all Python packages under a path.

    Finds all directories containing __init__.py and returns them
    as dotted package names (e.g., 'mloda.registry', 'mloda.registry.tests').
    Excludes build artifacts, common non-package directories, and paths
    that are configured as separate packages.
    """
    packages: list[str] = []
    base_path = Path(pkg_path)
    exclude_dirs = {"build", "dist", ".tox", ".venv", "__pycache__", ".egg-info", "tests"}
    exclude_paths = exclude_paths or []

    if not base_path.exists():
        return packages

    # Walk directory tree looking for __init__.py files
    for init_file in base_path.rglob("__init__.py"):
        pkg_dir = init_file.parent
        pkg_dir_str = str(pkg_dir)
        # Skip excluded directories
        if any(excluded in pkg_dir.parts for excluded in exclude_dirs):
            continue
        # Skip paths that are configured as separate packages
        if any(pkg_dir_str == excl or pkg_dir_str.startswith(excl + "/") for excl in exclude_paths):
            continue
        # Convert path to dotted package name (relative to repo root, not package root)
        # pkg_path like "mloda/community/feature_groups/example" -> start from "mloda"
        pkg_name = pkg_dir_str.replace("/", ".").replace("\\", ".")
        packages.append(pkg_name)

    return sorted(packages)


def load_configs() -> tuple[dict[str, Any], dict[str, Any]]:
    """Load shared and packages configuration."""
    with open(SHARED_CONFIG, "rb") as f:
        shared = tomllib.load(f)
    with open(PACKAGES_CONFIG, "rb") as f:
        packages = tomllib.load(f)
    return shared, packages


def generate_pyproject(
    pkg_name: str,
    pkg_config: dict[str, Any],
    shared: dict[str, Any],
    all_packages: dict[str, dict[str, Any]],
) -> str:
    """Generate pyproject.toml content for a package."""
    lines = [HEADER]

    # Build system
    lines.append("[build-system]")
    lines.append(f"requires = {to_toml_list(shared['build-system']['requires'])}")
    lines.append(f'build-backend = "{shared["build-system"]["build-backend"]}"')
    lines.append("")

    # Project section
    lines.append("[project]")
    lines.append(f'name = "{pkg_name}"')
    lines.append(f'version = "{shared["project"]["version"]}"')
    lines.append(f'description = "{pkg_config["description"]}"')

    if pkg_config.get("has_readme"):
        lines.append('readme = "README.md"')

    # License - infer from path (enterprise = proprietary), or use default
    defaults = shared.get("defaults", {})
    if pkg_config["path"].startswith("mloda/enterprise"):
        license_val = "LicenseRef-Proprietary"
    else:
        license_val = defaults.get("license", "Apache-2.0")
    lines.append(f'license = "{license_val}"')

    # Authors - format as inline table
    authors = shared["project"]["authors"]
    author_strs = [f'{{ name = "{a["name"]}", email = "{a["email"]}" }}' for a in authors]
    lines.append(f"authors = [{', '.join(author_strs)}]")

    # Dependencies
    deps = pkg_config.get("dependencies", [])
    lines.append(f"dependencies = {to_toml_list(deps)}")

    lines.append(f'requires-python = "{shared["project"]["requires-python"]}"')
    lines.append("")

    # Optional dependencies - merge defaults with package-specific
    # Skip defaults for specific packages
    skip_defaults = pkg_name in ("mloda-testing", "mloda-community", "mloda-enterprise")
    default_opt_deps = {} if skip_defaults else defaults.get("optional_dependencies", {})
    pkg_opt_deps = pkg_config.get("optional_dependencies", {})
    merged_opt_deps = {**default_opt_deps, **pkg_opt_deps}
    if merged_opt_deps:
        lines.append("[project.optional-dependencies]")
        for group, deps in merged_opt_deps.items():
            lines.append(f"{group} = {to_toml_list(deps)}")
        lines.append("")

    # URLs
    lines.append("[project.urls]")
    for key, value in shared["project"]["urls"].items():
        lines.append(f'{key} = "{value}"')
    lines.append("")

    # Setuptools config - infer meta-package from workspace_deps
    if "workspace_deps" in pkg_config:
        lines.append("[tool.setuptools]")
        lines.append("packages = []")
    else:
        # Calculate relative path from package dir to repo root
        pkg_path = Path(pkg_config["path"])
        depth = len(pkg_path.parts)
        rel_path = "/".join([".."] * depth)

        # Only exclude sub-packages that are listed in optional_dependencies
        # Bundle packages (like mloda-community) don't have optional deps, so they include everything
        opt_deps = pkg_config.get("optional_dependencies", {})
        optional_pkg_names = set()
        for deps in opt_deps.values():
            optional_pkg_names.update(deps)

        # Map optional dependency names to their paths
        exclude_paths = [all_packages[dep_name]["path"] for dep_name in optional_pkg_names if dep_name in all_packages]

        # Discover packages from filesystem, excluding optional sub-packages
        packages = discover_packages(pkg_config["path"], exclude_paths)

        lines.append("[tool.setuptools]")
        lines.append(f'package-dir = {{"" = "{rel_path}"}}')
        lines.append(f"packages = {to_toml_list(packages)}")
    lines.append("")

    # UV sources for workspace deps
    # Also add mloda-testing for top-level packages that get it from defaults
    pkg_path = Path(pkg_config["path"])
    depth = len(pkg_path.parts)
    gets_default_dev_deps = pkg_name not in ("mloda-testing", "mloda-community", "mloda-enterprise")

    if "workspace_deps" in pkg_config:
        lines.append("[tool.uv.sources]")
        for dep in pkg_config["workspace_deps"]:
            lines.append(f"{dep} = {{ workspace = true }}")
        lines.append("")
    elif gets_default_dev_deps and depth <= 2:
        lines.append("[tool.uv.sources]")
        lines.append("mloda-testing = { workspace = true }")
        lines.append("")

    return "\n".join(lines)


def get_pyproject_path(pkg_config: dict[str, Any]) -> Path:
    """Get the pyproject.toml path for a package."""
    return Path(pkg_config["path"]) / "pyproject.toml"


def generate_workspace_members(packages: dict[str, Any]) -> str:
    """Generate the workspace members TOML section."""
    members = sorted(pkg["path"] for pkg in packages.values())
    lines = [
        "# AUTO-GENERATED workspace members from config/packages.toml",
        "# Do not edit manually - run: python scripts/generate_pyproject.py",
        "[tool.uv.workspace]",
        "members = [",
    ]
    for member in members:
        lines.append(f'    "{member}",')
    lines.append("]")
    return "\n".join(lines)


def update_workspace_members(packages: dict[str, Any], check: bool = False) -> tuple[bool, str]:
    """Update or check workspace members in root pyproject.toml.

    The workspace members section is always placed at the bottom of the file.
    Returns (success, message) tuple.
    """
    if not ROOT_PYPROJECT.exists():
        return False, f"{ROOT_PYPROJECT}: missing"

    content = ROOT_PYPROJECT.read_text()
    expected_section = generate_workspace_members(packages)

    # Pattern to match [tool.uv.workspace] section (with optional comment header)
    # Only match 1-2 preceding newlines to avoid eating content from previous sections
    pattern = r"\n{1,2}(?:# AUTO-GENERATED workspace members[^\n]*\n# Do not edit manually[^\n]*\n)?\[tool\.uv\.workspace\]\nmembers = \[\n(?:    \"[^\"]+\",\n)*\]\n?"

    match = re.search(pattern, content)

    if match:
        current_section = match.group(0).strip()
        is_at_end = match.end() >= len(content.rstrip())
        content_matches = current_section == expected_section

        if content_matches and is_at_end:
            return True, "up-to-date"

        if check:
            if not content_matches:
                return False, f"{ROOT_PYPROJECT}: workspace members out of date"
            else:
                return False, f"{ROOT_PYPROJECT}: workspace members not at end of file"

        # Remove existing section and append to bottom
        content_without = content[: match.start()] + content[match.end() :]
        content_without = content_without.rstrip() + "\n\n"
        new_content = content_without + expected_section + "\n"
    else:
        if check:
            return False, f"{ROOT_PYPROJECT}: [tool.uv.workspace] section not found"

        # Append to bottom
        new_content = content.rstrip() + "\n\n" + expected_section + "\n"

    ROOT_PYPROJECT.write_text(new_content)
    return True, "updated"


def main() -> int:
    parser = argparse.ArgumentParser(description="Generate pyproject.toml files")
    parser.add_argument("--check", action="store_true", help="Check if files are up-to-date")
    args = parser.parse_args()

    shared, packages_config = load_configs()
    packages = packages_config.get("packages", {})

    errors = []
    updated = []

    for pkg_name, pkg_config in packages.items():
        pyproject_path = get_pyproject_path(pkg_config)
        expected_content = generate_pyproject(pkg_name, pkg_config, shared, packages)

        if args.check:
            if pyproject_path.exists():
                current_content = pyproject_path.read_text()
                if current_content != expected_content:
                    errors.append(f"{pyproject_path}: out of date")
            else:
                errors.append(f"{pyproject_path}: missing")
        else:
            # Ensure parent directory exists
            pyproject_path.parent.mkdir(parents=True, exist_ok=True)
            pyproject_path.write_text(expected_content)
            updated.append(str(pyproject_path))
            print(f"  ✓ {pyproject_path}")

    # Handle workspace members
    workspace_ok, workspace_msg = update_workspace_members(packages, check=args.check)

    if args.check:
        if not workspace_ok:
            errors.append(workspace_msg)
        if errors:
            print("❌ Files out of date:")
            for e in errors:
                print(f"  - {e}")
            print("\nRun 'python scripts/generate_pyproject.py' to regenerate")
            return 1
        print(f"✅ All {len(packages)} pyproject.toml files are up-to-date")
        print("✅ Workspace members are up-to-date")
        return 0

    if workspace_ok and workspace_msg == "updated":
        print(f"  ✓ {ROOT_PYPROJECT} (workspace members)")

    print(f"\n✅ Generated {len(updated)} pyproject.toml files")
    return 0


if __name__ == "__main__":
    sys.exit(main())
